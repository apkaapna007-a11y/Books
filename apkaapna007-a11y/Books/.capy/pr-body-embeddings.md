This PR adds scripts to compute 1536‑d embeddings for each chunk and validate similarity search.

Added
- scripts/requirements.txt — openai, psycopg, dotenv
- scripts/compute_embeddings.py — batches through rows with NULL embedding, calls OpenAI text-embedding-3-small, updates embedding vector(1536) with retries/backoff
- scripts/validate_similarity.py — embeds a query and returns the top 10 most similar chunks by vector distance
- scripts/README.md — setup and run instructions

Usage
1) Ensure `sql/pgvector_setup.sql` was applied and `uploads/chunks.csv` was imported into `public.nelson_book_contents`.
2) Set env in `.env` (DATABASE_URL, OPENAI_API_KEY, etc.).
3) `pip install -r scripts/requirements.txt`
4) `python scripts/compute_embeddings.py`
5) `python scripts/validate_similarity.py "asthma corticosteroid"`

Notes
- Model: `text-embedding-3-small` (1536-d) to match column `vector(1536)`
- Default batch size 100 with simple backoff
- Safe to re-run; only fills NULL embeddings


₍ᐢ•(ܫ)•ᐢ₎ Generated by [Capy](https://capy.ai) ([view task](https://capy.ai/project/6575c76f-ba70-41c6-955f-1f3b723a9a54/task/3e182ba6-df4d-499d-995d-c3dc54a521e7))